{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gothic-recording",
   "metadata": {},
   "source": [
    "#### Author: Tejaswini Patil\n",
    "#### Reg No:20MAI0044\n",
    "### Lab Assignment - 4: Task 1 - Implement the AlexNet ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-retreat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outside-tower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 25,678,184\n",
      "Trainable params: 25,678,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224, 224, 3), kernel_size=(11, 11), strides=(4, 4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd Fully Connected Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "radical-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 60000 training images and 10000 testing images\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "partial-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,676,266\n",
      "Trainable params: 1,676,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 64s 58ms/step - loss: 0.4654 - accuracy: 0.8470 - val_loss: 0.0334 - val_accuracy: 0.9901\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 54s 57ms/step - loss: 0.0857 - accuracy: 0.9737 - val_loss: 0.0298 - val_accuracy: 0.9898\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 52s 55ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.0316 - val_accuracy: 0.9899\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 52s 55ms/step - loss: 0.0533 - accuracy: 0.9838 - val_loss: 0.0231 - val_accuracy: 0.9933\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 52s 55ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.0224 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18dd6e6a748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras.utils.np_utils conveniently has this built in\n",
    "classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "# Step 3:\n",
    "# Build our Neural Network\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=32, input_shape=(28, 28, 1), kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# Fully Connected layer\n",
    "model.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output Layer\n",
    "# important to have dense 10, since we have 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "            rotation_range=8,\n",
    "            width_shift_range=0.08,\n",
    "            shear_range=0.3,\n",
    "            height_shift_range=0.08,\n",
    "            zoom_range=0.08\n",
    "            )\n",
    "test_gen = ImageDataGenerator()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "# Generator to \"flow\" in the input images and labels into our model\n",
    "# Takes batch_size as a parameter\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "#################################################\n",
    "# Step 5:\n",
    "# Do the training!\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=60000//BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=10000//BATCH_SIZE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assured-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3.6.6\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take first image in testing dataset\n",
    "to_predict = X_test[0]\n",
    "# reshape from (28, 28, 1) --> (1, 28, 28, 1)\n",
    "to_predict = np.expand_dims(to_predict, axis=0)\n",
    "\n",
    "# make prediction: this gives probability distribution over all classes\n",
    "model.predict(to_predict)\n",
    "\n",
    "# This returns the class with the highest probability\n",
    "model.predict_classes(to_predict)\n",
    "\n",
    "# Let's compare with actual label:\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adult-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_mnist_model.h5')\n",
    "\n",
    "model = load_model('my_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-stewart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-house",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-myrtle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-capacity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-residence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-copying",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
